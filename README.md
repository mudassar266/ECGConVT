ECGConVT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Original ECG image folders (MI, PMI, AHB, Normal)
â”‚   â””â”€â”€ processed/     # Preprocessed .npy, TFRecord, or resized images
â”œâ”€â”€ src/               # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py      # YAML config loader
â”‚   â”œâ”€â”€ data_loader.py # Dataset loading & preprocessing
â”‚   â”œâ”€â”€ xception_model.py
â”‚   â”œâ”€â”€ vit_model.py
â”‚   â”œâ”€â”€ fusion_model.py
â”‚   â”œâ”€â”€ train.py       # Training script
â”‚   â”œâ”€â”€ evaluate.py    # Evaluation & metrics
â”‚   â””â”€â”€ utils.py       # Plotting & helpers
â”œâ”€â”€ notebooks/         # Jupyter notebooks for exploration & reports
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_architectures.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”œâ”€â”€ scripts/           # Shell scripts (run_train.sh, run_eval.sh)
â”œâ”€â”€ reports/           # Saved figures & metrics (classification_report.json, cm_*.png)
â”œâ”€â”€ config.yaml        # Experiment configuration
â”œâ”€â”€ environment.yml    # Conda environment definition
â”œâ”€â”€ .gitignore         # Files & folders to exclude
â””â”€â”€ LICENSE            # License (e.g., MIT)

ğŸš€ Installation
git clone https://github.com/your-username/ECGConVT.git
cd ECGConVT

Create conda environment
conda env create -f environment.yml
conda activate ECGConVT

Install additional dependencies (if using pip)
pip install -r requirements.txt

ğŸ—‚ï¸ Data Preparation
Structure: Place your ECG images in data/raw/ with four subdirectories:
MI/
PMI/
AHB/
Normal/
Ignore data in git: Ensure data/raw/ and data/processed/ are listed in .gitignore.
Preprocessing: The loader (src/data_loader.py) will resize to 299Ã—299, normalize, and split into train/val/test.

âš™ï¸ Configuration
Edit config.yaml to adjust paths and hyperparameters:

data_dir: "data/raw"
img_size: [299, 299]
batch_size: 32
val_split: 0.2
test_split: 0.1
seed: 42
xcep_weights: "imagenet"
vit_url: "https://tfhub.dev/google/vit_base_patch16_224/feature_vector/1"
trainable_backbones: false
mlp_units: [512, 256]
dropout_rate: 0.5
optimizer: "Adam"
learning_rate: 1e-4
epochs: 200
checkpoint_dir: "checkpoints"
tensorboard_logdir: "logs/"
history_path: "reports/history.json"

ğŸƒ Usage

Training
python src/train.py --config config.yaml

Evaluation
python src/evaluate.py --model_path checkpoints/best_model.h5 --test_dir data/raw


ğŸ““ Notebooks
Reuse the provided notebooks for data exploration, architecture visualization, and result analysis:
notebooks/01_data_exploration.ipynb
notebooks/02_model_architectures.ipynb
notebooks/03_results_analysis.ipynb

